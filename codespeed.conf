# Config file for ReBench
# Config format is YAML (see http://yaml.org/ for detailed spec)

# this run definition will be choosen if no parameters are given to rebench.py
standard_run: all
standard_data_file: 'codespeed.data'

reporting:
    # results can also be reported to a codespeed instance
    # see: https://github.com/tobami/codespeed
    csv_file: latest-runs.csv
    csv_locale: de_DE.UTF-8
    codespeed:
        url: http://som-speed.stefan-marr.de/result/add/json/

# settings and requirements for statistic evaluation
statistics:
    min_runs: 10
    max_runs: 10
    confidence_level: 0.90
    error_margin: 0.005
 
# settings for quick runs, useful for fast feedback during experiments
quick_runs:
    min_runs: 3
    max_runs: 10
    max_time: 60   # time in seconds

# definition of benchmark suites
benchmark_suites:
    macro-startup:
        performance_reader: LogPerformance
        command: ":/home/smarr/.local/SOM/Examples/Benchmarks/Richards:/home/smarr/.local/SOM/Examples/Benchmarks/DeltaBlue ~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 600
        benchmarks:
            - Richards:
                extra_args: "1 0 10"
                codespeed_name: "Richards [>"
            - DeltaBlue:
                extra_args: "1 0 6000"
                codespeed_name: "DeltaBlue [>"

    macro-steady:
        performance_reader: LogPerformance
        command: ":/home/smarr/.local/SOM/Examples/Benchmarks/Richards:/home/smarr/.local/SOM/Examples/Benchmarks/DeltaBlue ~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som  %(benchmark)s "
        max_runtime: 600
        benchmarks:
            - Richards:
                extra_args: "1 10 10"
                codespeed_name: "Richards >]"
            - DeltaBlue:
                extra_args: "1 10 6000"
                codespeed_name: "DeltaBlue >]"

    micro-startup-100:
        performance_reader: LogPerformance
        command: " ~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 30
        benchmarks:
            - Fibonacci:
                extra_args: "1 0 300"
                codespeed_name: "Fibonacci 100x [>"
            - Dispatch:
                extra_args: "1 0 2000"
                codespeed_name: "Dispatch 100x [>"
            - Bounce:
                extra_args: "1 0 200"
                codespeed_name: "Bounce 100x [>"
            - Loop:
                extra_args: "1 0 1000"
                codespeed_name: "Loop 100x [>"
            - Permute:
                extra_args: "1 0 300"
                codespeed_name: "Permute 100x [>"
            - Queens:
                extra_args: "1 0 200"
                codespeed_name: "Queens 100x [>"
            - List:
                extra_args: "1 0 200"
                codespeed_name: "List 100x [>"
            - Recurse:
                extra_args: "1 0 300"
                codespeed_name: "Recurse 100x [>"
            - Storage:
                extra_args: "1 0 200"
                codespeed_name: "Storage 100x [>"
            - Sieve:
                extra_args: "1 0 500"
                codespeed_name: "Sieve 100x [>"
            - BubbleSort:
                extra_args: "1 0 300"
                codespeed_name: "BubbleSort 100x [>"
            - QuickSort:
                extra_args: "1 0 300"
                codespeed_name: "QuickSort 100x [>"
            - Sum:
                extra_args: "1 0 1000"
                codespeed_name: "Sum 100x [>"
            - Towers:
                extra_args: "1 0 200"
                codespeed_name: "Towers 100x [>"
            - TreeSort:
                extra_args: "1 0 100"
                codespeed_name: "TreeSort 100x [>"
            - IntegerLoop:
                extra_args: "1 0 800"
                codespeed_name: "IntegerLoop 100x [>"
            - FieldLoop:
                extra_args: "1 0 300"
                codespeed_name: "FieldLoop 100x [>"
            - WhileLoop:
                extra_args: "1 0 3000"
                codespeed_name: "WhileLoop 100x [>"

    micro-startup:
        performance_reader: LogPerformance
        command: " ~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        max_runtime: 200000
        benchmarks:
            - Fibonacci:
                extra_args: "1 0 3"
                codespeed_name: "Fibonacci [>"
            - Dispatch:
                extra_args: "1 0 20"
                codespeed_name: "Dispatch [>"
            - Bounce:
                extra_args: "1 0 2"
                codespeed_name: "Bounce [>"
            - Loop:
                extra_args: "1 0 10"
                codespeed_name: "Loop [>"
            - Permute:
                extra_args: "1 0 3"
                codespeed_name: "Permute [>"
            - Queens:
                extra_args: "1 0 2"
                codespeed_name: "Queens [>"
            - List:
                extra_args: "1 0 2"
                codespeed_name: "List [>"
            - Recurse:
                extra_args: "1 0 3"
                codespeed_name: "Recurse [>"
            - Storage:
                extra_args: "1 0 2"
                codespeed_name: "Storage [>"
            - Sieve:
                extra_args: "1 0 5"
                codespeed_name: "Sieve [>"
            - BubbleSort:
                extra_args: "1 0 3"
                codespeed_name: "BubbleSort [>"
            - QuickSort:
                extra_args: "1 0 3"
                codespeed_name: "QuickSort [>"
            - Sum:
                extra_args: "1 0 10"
                codespeed_name: "Sum [>"
            - Towers:
                extra_args: "1 0 2"
                codespeed_name: "Towers [>"
            - TreeSort:
                extra_args: "1 0 1"
                codespeed_name: "TreeSort [>"
            - IntegerLoop:
                extra_args: "1 0 8"
                codespeed_name: "IntegerLoop [>"
            - FieldLoop:
                extra_args: "1 0 3"
                codespeed_name: "FieldLoop [>"
            - WhileLoop:
                extra_args: "1 0 30"
                codespeed_name: "WhileLoop [>"

    micro-steady-100:
        performance_reader: LogPerformance
        command: " ~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        #input_sizes:
        #    - benchmarking.image ReBenchHarness
        max_runtime: 30
        benchmarks:
            - Fibonacci:
                extra_args: "1 2 300"
                codespeed_name: "Fibonacci 100x >]"
            - Dispatch:
                extra_args: "1 2 2000"
                codespeed_name: "Dispatch 100x >]"
            - Bounce:
                extra_args: "1 2 200"
                codespeed_name: "Bounce 100x >]"
            - Loop:
                extra_args: "1 2 1000"
                codespeed_name: "Loop 100x >]"
            - Permute:
                extra_args: "1 2 300"
                codespeed_name: "Permute 100x >]"
            - Queens:
                extra_args: "1 2 200"
                codespeed_name: "Queens 100x >]"
            - List:
                extra_args: "1 2 200"
                codespeed_name: "List 100x >]"
            - Recurse:
                extra_args: "1 2 300"
                codespeed_name: "Recurse 100x >]"
            - Storage:
                extra_args: "1 2 200"
                codespeed_name: "Storage 100x >]"
            - Sieve:
                extra_args: "1 2 500"
                codespeed_name: "Sieve 100x >]"
            - BubbleSort:
                extra_args: "1 2 300"
                codespeed_name: "BubbleSort 100x >]"
            - QuickSort:
                extra_args: "1 2 300"
                codespeed_name: "QuickSort 100x >]"
            - Sum:
                extra_args: "1 2 1000"
                codespeed_name: "Sum 100x >]"
            - Towers:
                extra_args: "1 2 200"
                codespeed_name: "Towers 100x >]"
            - TreeSort:
                extra_args: "1 2 100"
                codespeed_name: "TreeSort 100x >]"
            - IntegerLoop:
                extra_args: "1 2 800"
                codespeed_name: "IntegerLoop 100x >]"
            - FieldLoop:
                extra_args: "1 2 300"
                codespeed_name: "FieldLoop 100x >]"
            - WhileLoop:
                extra_args: "1 2 3000"
                codespeed_name: "WhileLoop 100x >]"
    micro-steady:
        performance_reader: LogPerformance
        command: " ~/.local/SOM/Examples/Benchmarks/BenchmarkHarness.som %(benchmark)s "
        #input_sizes:
        #    - benchmarking.image ReBenchHarness
        max_runtime: 200000
        benchmarks:
            - Fibonacci:
                extra_args: "1 2 3"
                codespeed_name: "Fibonacci >]"
            - Dispatch:
                extra_args: "1 2 20"
                codespeed_name: "Dispatch >]"
            - Bounce:
                extra_args: "1 2 2"
                codespeed_name: "Bounce >]"
            - Loop:
                extra_args: "1 2 10"
                codespeed_name: "Loop >]"
            - Permute:
                extra_args: "1 2 3"
                codespeed_name: "Permute >]"
            - Queens:
                extra_args: "1 2 2"
                codespeed_name: "Queens >]"
            - List:
                extra_args: "1 2 2"
                codespeed_name: "List >]"
            - Recurse:
                extra_args: "1 2 3"
                codespeed_name: "Recurse >]"
            - Storage:
                extra_args: "1 2 2"
                codespeed_name: "Storage >]"
            - Sieve:
                extra_args: "1 2 5"
                codespeed_name: "Sieve >]"
            - BubbleSort:
                extra_args: "1 2 3"
                codespeed_name: "BubbleSort >]"
            - QuickSort:
                extra_args: "1 2 3"
                codespeed_name: "QuickSort >]"
            - Sum:
                extra_args: "1 2 10"
                codespeed_name: "Sum >]"
            - Towers:
                extra_args: "1 2 2"
                codespeed_name: "Towers >]"
            - TreeSort:
                extra_args: "1 2 1"
                codespeed_name: "TreeSort >]"
            - IntegerLoop:
                extra_args: "1 2 8"
                codespeed_name: "IntegerLoop >]"
            - FieldLoop:
                extra_args: "1 2 3"
                codespeed_name: "FieldLoop >]"
            - WhileLoop:
                extra_args: "1 2 30"
                codespeed_name: "WhileLoop >]"

# VMs have a name and are specified by a path and the binary to be executed
virtual_machines:
    SOM:
        path: .
        binary: som.sh
        args: "-cp Smalltalk"
    TruffleSOM-interpreter:
        path: . 
        binary: som.sh
        args: "-cp Smalltalk"
    TruffleSOM-graal:
        path: . 
        binary: graal.sh
        args: "-cp /home/smarr/Projects/RoarVM-buildslave/TruffleSOM/build/Smalltalk"
    CSOM:
        path: .
        binary: CSOM
        args: "-cp Smalltalk"
    SOMpp:
        path: .
        binary: som.sh
        args: "-cp Smalltalk"
    PySOM:
        path: .
        binary: som.sh
        args: "-cp Smalltalk"
    RPySOM-interpreter:
        path: .
        binary: RPySOM-no-jit
        args: "-cp Smalltalk"
    RPySOM-jit:
        path: .
        binary: RPySOM-jit
        args: "-cp Smalltalk"
        
# define the benchmarks to be executed for a re-executable benchmark run
run_definitions:
    SOM:
        description: All benchmarks on SOM (Java, bytecode-based)
        actions: benchmark
        benchmark:
            - micro-startup-100
            - micro-steady-100
            - micro-startup
            - micro-steady
            - macro-startup
            - macro-steady
        executions: SOM
    TruffleSOM:
        description: All benchmarks on TruffleSOM (Java, AST Interpreter)
        actions: benchmark
        benchmark:
            - micro-startup
            - micro-steady
            - micro-startup-100
            - micro-steady-100
            - macro-startup
            - macro-steady
        executions:
            - TruffleSOM-interpreter
            - TruffleSOM-graal
    CSOM:
        description: All benchmarks on CSOM
        actions: benchmark
        benchmark:
            - micro-startup
            - macro-startup
        executions:
            - CSOM
    SOMpp:
        description: All benchmarks on SOM++
        actions: benchmark
        benchmark:
            - micro-startup
            - micro-startup-100
            - macro-startup
        executions:
            - SOMpp
    PySOM:
        description: All benchmarks on PySOM
        actions: benchmark
        benchmark:
            - micro-startup
            - micro-steady
            - macro-startup
        executions:
            - PySOM
    RPySOM:
        description: All benchmarks on RPySOM
        actions: benchmark
        benchmark:
            - micro-startup
            - micro-steady
            - micro-startup-100
            - micro-steady-100
            - macro-startup
            - macro-steady
        executions:
            - RPySOM-interpreter
            - RPySOM-jit
